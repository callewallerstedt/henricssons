#!/usr/bin/env python3
"""
Skrapar Henricssons “Bilder & exempel”:

henricssons_bilder/
├─ batstolar-dynor/
├─ vavprover-ovriga/
├─ motorbatar/
├─ segelbatar/
├─ specialsommnad-skraddarsytt/
├─ sunbrella-plus-kollektion-vavprover/
└─ okategoriserad/
    └─ <slug>/<slug>_01.jpg …

Metadata sparas i henricssons_bilder/models_meta.json
"""

import re, json, pathlib, urllib.parse, concurrent.futures, requests, bs4
from unidecode import unidecode

BASE     = "https://www.henricssonsbatkapell.se"
START    = f"{BASE}/bilder-och-exempel"
ROOTDIR  = pathlib.Path("henricssons_bilder")
THREADS  = 8

sess = requests.Session()
sess.headers["User-Agent"] = "HenricssonsScraper/5.1"

slug_re = re.compile(r"^/exempel/([a-z0-9\-]+)$", re.I)

# ── kategorimappning ────────────────────────────────────────────────────────
def canon(label: str) -> str:
    l = label.lower()
    if "motorbåt" in l:                      return "Motorbåtar"
    if "segelbåt" in l:                      return "Segelbåtar"
    if "sunbrella" in l:                     return "Sunbrella Plus Kollektion vävprover"
    if "special" in l or "skräddarsytt" in l:return "Specialsömnad & Skräddarsytt"
    if "färgprover" in l:                    return "Vävprover övriga"
    if "stol" in l or "dyna" in l:           return "Båtstolar & Dynor"
    return "Okategoriserad"

def slugify(txt: str) -> str:
    return re.sub(r"[^a-z0-9]+", "-", unidecode(txt.lower())).strip("-") or "okategoriserad"

# ── hämta index & slug → kategori ───────────────────────────────────────────
index_html = sess.get(START, timeout=20).text
index_soup = bs4.BeautifulSoup(index_html, "html.parser")

slug_cat = {}
for card in index_soup.select(".example-item"):
    href = card.select_one("a[href]")["href"]
    m = slug_re.match(href)
    if not m: continue
    slug = m.group(1)
    label = card.select_one(".category-label")
    slug_cat[slug] = canon(label.get_text(strip=True) if label else "")

links = [urllib.parse.urljoin(BASE, f"/exempel/{s}") for s in slug_cat]

meta = {}

# ── skrapa varje gallerisida ────────────────────────────────────────────────
def scrape(url: str):
    slug = slug_re.search(urllib.parse.urlparse(url).path).group(1)
    soup = bs4.BeautifulSoup(sess.get(url, timeout=20).text, "html.parser")

    manuf = soup.select_one("#tillverkare")
    manuf = manuf.get_text(strip=True) if manuf else ""
    model = soup.select_one("#modell")
    model = model.get_text(strip=True) if model else ""

    # fallback – försök dela första ordet = tillverkare, resten = modell
    if not manuf and model:
        parts = model.split(maxsplit=1)
        if len(parts) == 2:
            manuf, model = parts

    info = {div.select_one(".more-info-label").get_text(strip=True)[:-1].lower():
            div.select_one(".more-info-text").get_text(strip=True)
            for div in soup.select(".more-info-text-div")}

    category = canon(slug_cat.get(slug, info.get("variant", "")))

    urls = set()
    urls.update(i["src"].split("?")[0] for i in soup.select("img.example-top-image"))
    for s in soup.select("script.w-json"):
        try:
            data = json.loads(s.string)
            urls.update(i["url"].split("?")[0] for i in data.get("items", [])
                        if i.get("type") == "image")
        except Exception:
            pass

    folder = ROOTDIR / slugify(category) / slug
    folder.mkdir(parents=True, exist_ok=True)

    files = []
    for idx, img_url in enumerate(sorted(urls), 1):
        ext  = pathlib.Path(urllib.parse.urlparse(img_url).path).suffix.lower()
        name = f"{slug}_{idx:02d}{ext}"
        dest = folder / name
        if not dest.exists():
            try:
                with sess.get(img_url, stream=True, timeout=30) as r, open(dest, "wb") as f:
                    for chunk in r.iter_content(8192):
                        f.write(chunk)
            except Exception:
                continue
        files.append(str(dest.relative_to(ROOTDIR)))

    meta[slug] = {
        "manufacturer": manuf,
        "model": model,
        "description": info.get("beskrivning", ""),
        "variant": info.get("variant", ""),
        "delivery": info.get("leveransinfo", ""),
        "category": category,
        "images": files,
        "source": url
    }
    print(f"{slug:25} {category:35} {len(files)} bilder")

with concurrent.futures.ThreadPoolExecutor(THREADS) as ex:
    ex.map(scrape, links)

ROOTDIR.mkdir(exist_ok=True)
(ROOTDIR / "models_meta.json").write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")
print("✓ färdigt – allt sparat i henricssons_bilder/")
